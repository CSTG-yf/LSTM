# å°æ ·æœ¬çº¿è·¯æ—¶åºé¢„æµ‹ - æ ‘æ¨¡å‹é›†æˆæ–¹æ¡ˆ

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

æœ¬æ–¹æ¡ˆä¸“ä¸º**å°æ ·æœ¬ï¼ˆ600æ¡/çº¿è·¯ï¼‰æ—¶ç©ºç‰¹å¾é¢„æµ‹**è®¾è®¡ï¼ŒåŸºäºæ ‘æ¨¡å‹é›†æˆå­¦ä¹ ï¼Œæœ€å¤§åŒ–åˆ©ç”¨"çº¿è·¯ç‰¹å¾"å’Œ"æ—¶é—´ä¾èµ–å…³ç³»"ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜é¢„æµ‹å‡†ç¡®ç‡ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

âœ… **ä¸¥æ ¼æ—¶åºåˆ‡åˆ†** - å‰å‘éªŒè¯ï¼ˆWalk-Forward Validationï¼‰ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²  
âœ… **æ ‘æ¨¡å‹é›†æˆ** - XGBoost + LightGBM + Ridge Regression  
âœ… **é˜²æ­¢è¿‡æ‹Ÿåˆ** - æ­£åˆ™åŒ– + æ ‘æ·±é™åˆ¶ + é‡‡æ ·ç­–ç•¥  
âœ… **å¯¹æ•°å˜æ¢** - å¤„ç†ååº¦åˆ†å¸ƒ  
âœ… **åŠ æƒé›†æˆ** - åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–æ¨¡å‹æƒé‡  

---

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
Pytorch/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ model_config.yaml          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ timeseries_dataset.py  # æ—¶åºæ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tree_models.py         # æ ‘æ¨¡å‹è®­ç»ƒ
â”‚   â”‚   â””â”€â”€ ensemble.py            # æ¨¡å‹é›†æˆ
â”‚   â”œâ”€â”€ train.py                   # ä¸»è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ predict.py                 # é¢„æµ‹è„šæœ¬
â”œâ”€â”€ Dataset/
â”‚   â””â”€â”€ visitordata.csv            # è®­ç»ƒæ•°æ®
â”œâ”€â”€ outputs/                       # è¾“å‡ºç›®å½•
â”œâ”€â”€ requirements.txt               # ä¾èµ–åŒ…
â””â”€â”€ æ ‘æ¨¡å‹è®­ç»ƒæ–¹æ¡ˆè¯´æ˜.md         # æœ¬æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–ï¼š
- `xgboost>=1.7.0` - XGBoostæ¨¡å‹
- `lightgbm>=3.3.0` - LightGBMæ¨¡å‹
- `scikit-learn>=1.0.0` - Ridgeå›å½’å’Œè¯„ä¼°æŒ‡æ ‡
- `pandas, numpy, matplotlib, seaborn`

### 2. æ•°æ®å‡†å¤‡

æ•°æ®åº”åŒ…å«ä»¥ä¸‹ç‰¹å¾ï¼ˆå·²åœ¨ `visitordata.csv` ä¸­å‡†å¤‡å¥½ï¼‰ï¼š
- âœ… **æ»åç‰¹å¾**ï¼š`visitor_count_lag_1`, `visitor_count_lag_7`, `visitor_count_lag_30`
- âœ… **æ»‘åŠ¨çª—å£ç‰¹å¾**ï¼š`visitor_count_rolling_mean_3/7/14` ç­‰
- âœ… **çº¿è·¯ID**ï¼š`route_id`
- âœ… **æ—¥æœŸ**ï¼š`date`
- âœ… **ç›®æ ‡å˜é‡**ï¼š`visitor_count`
- âœ… **å…¶ä»–ç‰¹å¾**ï¼šå¤©æ°”ç±»å‹ã€å·¥ä½œæ—¥æ ‡è®°ã€è®¢å•æ•°ç­‰

### 3. è®­ç»ƒæ¨¡å‹

```bash
python src/train.py
```

è®­ç»ƒæµç¨‹ï¼š
1. åŠ è½½é…ç½®å’Œæ•°æ®
2. æ—¶åºåˆ‡åˆ†ï¼ˆè®­ç»ƒ:éªŒè¯:æµ‹è¯• = 67:17:16ï¼‰
3. è®­ç»ƒ XGBoostã€LightGBMã€Ridge ä¸‰ä¸ªæ¨¡å‹
4. åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–é›†æˆæƒé‡
5. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
6. ä¿å­˜æ¨¡å‹å’Œç»“æœ

### 4. æŸ¥çœ‹ç»“æœ

è®­ç»ƒå®Œæˆåï¼Œ`outputs/` ç›®å½•åŒ…å«ï¼š
- `xgboost_model.pkl` - XGBoostæ¨¡å‹
- `lightgbm_model.pkl` - LightGBMæ¨¡å‹
- `ridge_model.pkl` - Ridgeæ¨¡å‹
- `ensemble_weights.pkl` - é›†æˆæƒé‡
- `trainer.pkl` - è®­ç»ƒå™¨ï¼ˆå«å˜æ¢å‡½æ•°ï¼‰
- `evaluation_results.pkl` - è¯„ä¼°ç»“æœ
- `xgboost_feature_importance.png` - XGBoostç‰¹å¾é‡è¦æ€§å›¾
- `lightgbm_feature_importance.png` - LightGBMç‰¹å¾é‡è¦æ€§å›¾

### 5. ä½¿ç”¨æ¨¡å‹é¢„æµ‹

```bash
python src/predict.py --data Dataset/visitordata.csv --output outputs/predictions.csv
```

---

## âš™ï¸ é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ï¼š[`configs/model_config.yaml`](configs/model_config.yaml)

### å…³é”®å‚æ•°

#### æ•°æ®åˆ‡åˆ†
```yaml
data:
  train_ratio: 0.67  # è®­ç»ƒé›† 400æ¡
  val_ratio: 0.17    # éªŒè¯é›† 100æ¡
  test_ratio: 0.16   # æµ‹è¯•é›† 100æ¡
```

#### XGBoost å‚æ•°ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆä¼˜åŒ–ï¼‰
```yaml
xgboost:
  max_depth: 4              # æ ‘æ·±é™åˆ¶
  learning_rate: 0.05       # å°å­¦ä¹ ç‡
  subsample: 0.8            # è¡Œé‡‡æ ·
  colsample_bytree: 0.8     # åˆ—é‡‡æ ·
  reg_alpha: 1.0            # L1æ­£åˆ™åŒ–
  reg_lambda: 2.0           # L2æ­£åˆ™åŒ–
  min_child_weight: 3       # æœ€å°å¶å­æƒé‡
```

#### LightGBM å‚æ•°
```yaml
lightgbm:
  max_depth: 4
  learning_rate: 0.05
  num_leaves: 15            # å¶å­æ•° = 2^max_depth - 1
  subsample: 0.8
  reg_alpha: 1.0
  reg_lambda: 2.0
  min_child_samples: 10
```

---

## ğŸ“Š æ–¹æ¡ˆæ ¸å¿ƒç­–ç•¥

### 1. æ•°æ®é›†åˆ‡åˆ†ç­–ç•¥ï¼ˆä¸¥ç¦éšæœºåˆ‡åˆ†ï¼‰

**é—®é¢˜**ï¼šæ—¶é—´åºåˆ—é—®é¢˜ä¸­éšæœºåˆ‡åˆ†ä¼šå¯¼è‡´"æœªæ¥æ•°æ®æ³„éœ²"

**è§£å†³æ–¹æ¡ˆ**ï¼š
- âœ… æŒ‰æ—¥æœŸå‡åºæ’åˆ—
- âœ… å¯¹æ¯æ¡çº¿è·¯åˆ†åˆ«åˆ‡åˆ†ï¼ˆå‰å‘éªŒè¯ï¼‰
- âœ… è®­ç»ƒé›† â†’ éªŒè¯é›† â†’ æµ‹è¯•é›†ï¼ˆé¡ºåºä¸å¯é€†ï¼‰

```python
# ç¤ºä¾‹ï¼šæ¯æ¡çº¿è·¯600æ¡æ•°æ®
è®­ç»ƒé›†: å‰400æ¡ï¼ˆ67%ï¼‰
éªŒè¯é›†: 401-500æ¡ï¼ˆ17%ï¼‰
æµ‹è¯•é›†: 501-600æ¡ï¼ˆ16%ï¼‰
```

### 2. ç‰¹å¾å·¥ç¨‹

æ•°æ®å·²åŒ…å«ä»¥ä¸‹æ—¶åºç‰¹å¾ï¼š

#### A. æ»åç‰¹å¾ï¼ˆLag Featuresï¼‰
- `visitor_count_lag_1` - æ˜¨å¤©
- `visitor_count_lag_7` - ä¸Šå‘¨åŒæ—¥
- `visitor_count_lag_30` - ä¸ŠæœˆåŒæ—¥

#### B. æ»‘åŠ¨çª—å£ç‰¹å¾ï¼ˆRolling Windowï¼‰
- 3å¤©ã€7å¤©ã€14å¤©çš„ Meanã€Medianã€Std
- ä¾‹å¦‚ï¼š`visitor_count_rolling_mean_7`

#### C. å¤–éƒ¨ç‰¹å¾
- `day_of_week` - æ˜ŸæœŸå‡ 
- `IsWorkingDay` - æ˜¯å¦å·¥ä½œæ—¥
- `weather_type` - å¤©æ°”ç±»å‹

### 3. æ¨¡å‹é€‰æ‹©

**ä¸ºä»€ä¹ˆé€‰æ‹©æ ‘æ¨¡å‹ï¼Ÿ**
- âœ… å¯¹å°æ ·æœ¬ï¼ˆ600æ¡ï¼‰æ•°æ®è¡¨ç°ä¼˜ç§€
- âœ… å†…ç½®ç‰¹å¾é€‰æ‹©ï¼Œå¤„ç†é«˜ç»´ç‰¹å¾
- âœ… æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼ºï¼ˆé€šè¿‡æ­£åˆ™åŒ–ï¼‰
- âœ… æ— éœ€ç‰¹å¾ç¼©æ”¾
- âœ… å¯è§£é‡Šæ€§å¥½ï¼ˆç‰¹å¾é‡è¦æ€§ï¼‰

**ä¸‰æ¨¡å‹é›†æˆ**ï¼š
1. **XGBoost** - å¼ºå¤§çš„æ¢¯åº¦æå‡ï¼Œé€‚åˆå¤æ‚æ¨¡å¼
2. **LightGBM** - é«˜æ•ˆä¸”å¿«é€Ÿï¼Œå¶å­ä¼˜å…ˆç”Ÿé•¿
3. **Ridge Regression** - çº¿æ€§åŸºå‡†ï¼Œå¢åŠ å¤šæ ·æ€§

### 4. ç›®æ ‡å˜é‡å¤„ç†

**å¯¹æ•°å˜æ¢**ï¼š`y_transformed = log(1 + y)`

- âœ… å¤„ç†é•¿å°¾åˆ†å¸ƒ
- âœ… é™ä½å¼‚å¸¸å€¼å½±å“
- âœ… é¢„æµ‹åä½¿ç”¨ `expm1` è¿˜åŸ

### 5. æ¨¡å‹é›†æˆç­–ç•¥

**åŠ æƒå¹³å‡**ï¼ˆæƒé‡åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–ï¼‰ï¼š
```
y_pred = w1 * XGBoost + w2 * LightGBM + w3 * Ridge
```

æƒé‡è®¡ç®—ï¼šåŸºäºéªŒè¯é›†RMSEçš„å€’æ•°ï¼ˆæ€§èƒ½è¶Šå¥½ï¼Œæƒé‡è¶Šå¤§ï¼‰

---

## ğŸ“ˆ æ€§èƒ½è¯„ä¼°

æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„è¯„ä¼°æŒ‡æ ‡ï¼š
- **RMSE** - å‡æ–¹æ ¹è¯¯å·®
- **MAE** - å¹³å‡ç»å¯¹è¯¯å·®
- **RÂ²** - å†³å®šç³»æ•°
- **MAPE** - å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®

---

## ğŸ”§ è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰æ¨¡å‹å‚æ•°

ç¼–è¾‘ `configs/model_config.yaml`ï¼š

```yaml
training:
  xgboost:
    max_depth: 5      # å¢åŠ æ ‘æ·±ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰
    learning_rate: 0.03  # é™ä½å­¦ä¹ ç‡
    n_estimators: 1000   # å¢åŠ è¿­ä»£æ¬¡æ•°
```

### ä½¿ç”¨Python API

```python
from src.data.timeseries_dataset import load_timeseries_data
from src.models.tree_models import TreeModelTrainer
from src.models.ensemble import create_ensemble

# åŠ è½½æ•°æ®
(X_train, y_train), (X_val, y_val), (X_test, y_test), features = \
    load_timeseries_data('Dataset/visitordata.csv')

# è®­ç»ƒæ¨¡å‹
trainer = TreeModelTrainer(use_log_transform=True)
models = trainer.train_all_models(X_train, y_train, X_val, y_val)

# åˆ›å»ºé›†æˆ
ensemble = create_ensemble(
    models, X_val, y_val,
    inverse_transform_func=trainer.inverse_transform_target
)

# é¢„æµ‹
y_pred, _ = ensemble.predict(X_test, trainer.inverse_transform_target)
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

âš ï¸ **ä¸¥ç¦æ“ä½œ**ï¼š
- âŒ ä½¿ç”¨ `train_test_split` éšæœºåˆ‡åˆ†ï¼ˆä¼šå¯¼è‡´æ•°æ®æ³„éœ²ï¼‰
- âŒ åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåšå½’ä¸€åŒ–ï¼ˆåº”è¯¥åªåœ¨è®­ç»ƒé›†ä¸Šfitï¼‰
- âŒ ä½¿ç”¨æœªæ¥æ•°æ®çš„ç‰¹å¾ï¼ˆå¦‚t+1çš„lagç‰¹å¾ï¼‰

âœ… **æ¨èå®è·µ**ï¼š
- âœ… å§‹ç»ˆä¿æŒæ—¶é—´é¡ºåº
- âœ… æ¯æ¡çº¿è·¯ç‹¬ç«‹åˆ‡åˆ†
- âœ… ä½¿ç”¨æ—©åœï¼ˆearly stoppingï¼‰
- âœ… ç›‘æ§éªŒè¯é›†æ€§èƒ½

---

## ğŸ¯ æ€»ç»“

æœ¬æ–¹æ¡ˆé€šè¿‡ä»¥ä¸‹ç­–ç•¥å®ç°å°æ ·æœ¬çº¿è·¯é¢„æµ‹ï¼š

1. **æ—¶åºä¸¥æ ¼æ€§** - å‰å‘éªŒè¯ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²
2. **ç‰¹å¾å·¥ç¨‹** - æ»å+æ»‘åŠ¨çª—å£+æ—¶é—´ç‰¹å¾
3. **æ¨¡å‹é€‰æ‹©** - æ ‘æ¨¡å‹ï¼ŒæŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º
4. **æ­£åˆ™åŒ–** - L1/L2æ­£åˆ™+æ ‘æ·±é™åˆ¶+é‡‡æ ·
5. **é›†æˆå­¦ä¹ ** - ä¸‰æ¨¡å‹åŠ æƒå¹³å‡ï¼Œé™ä½æ–¹å·®
6. **å¯¹æ•°å˜æ¢** - å¤„ç†ååº¦ï¼Œæé«˜é²æ£’æ€§

**é¢„æœŸæ•ˆæœ**ï¼š
- æé«˜é¢„æµ‹å‡†ç¡®ç‡ï¼ˆé™ä½RMSE/MAEï¼‰
- å¢å¼ºæ³›åŒ–èƒ½åŠ›ï¼ˆæµ‹è¯•é›†æ€§èƒ½ç¨³å®šï¼‰
- å¯è§£é‡Šæ€§å¼ºï¼ˆç‰¹å¾é‡è¦æ€§åˆ†æï¼‰

---

## ğŸ“ è”ç³»ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æŸ¥çœ‹ä»£ç æ³¨é‡Šæˆ–ä¿®æ”¹é…ç½®æ–‡ä»¶è¿›è¡Œå®éªŒã€‚

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ‰
