# GPU è®­ç»ƒå’Œçº¿è·¯é¢„æµ‹æŸ¥è¯¢ç³»ç»Ÿ

## ğŸ“Œ å¿«é€Ÿå¼€å§‹

### 1. GPU è®­ç»ƒ

**ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒï¼ˆæ¨èï¼‰ï¼š**
```bash
python quick_demo.py --mode train --use_gpu
```

**ä½¿ç”¨ CPU è¿›è¡Œè®­ç»ƒï¼š**
```bash
python quick_demo.py --mode train --no_gpu
```

### 2. æŸ¥è¯¢é¢„æµ‹

**å•æ¬¡æŸ¥è¯¢ï¼ˆæŒ‡å®šçº¿è·¯å’Œæ—¥æœŸï¼‰ï¼š**
```bash
python quick_demo.py --mode query --route kyoto_nara-A --date 2024-06-15
```

**äº¤äº’å¼æŸ¥è¯¢ï¼ˆæ¨èï¼‰ï¼š**
```bash
python quick_demo.py --mode query --interactive
```

---

## ğŸ¯ è¯¦ç»†ä½¿ç”¨æŒ‡å—

### GPU è®­ç»ƒæ¨¡å¼

#### ä»€ä¹ˆæ˜¯ GPU è®­ç»ƒï¼Ÿ
GPU è®­ç»ƒåˆ©ç”¨å›¾å½¢å¤„ç†å™¨çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼ŒåŠ é€Ÿæ ‘æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚å¯¹äºä¸­ç­‰æ•°æ®é‡çš„ä»»åŠ¡ï¼ŒGPU è®­ç»ƒå¯ä»¥æ¯” CPU å¿« 5-10 å€ã€‚

#### ç³»ç»Ÿè¦æ±‚
- **NVIDIA GPU**ï¼šæ”¯æŒ CUDA Compute Capability 3.5 æˆ–æ›´é«˜
- **CUDA 11.0+** å’Œ **cuDNN 8.0+**
- **PyTorch** å’Œ **XGBoost/LightGBM** çš„ GPU æ”¯æŒ

#### æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
```python
import torch
print(torch.cuda.is_available())  # True è¡¨ç¤º GPU å¯ç”¨
print(torch.cuda.get_device_name(0))  # æ˜¾ç¤º GPU åç§°
```

#### è‡ªåŠ¨ GPU æ£€æµ‹
è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ GPUï¼š
```
âœ“ æ£€æµ‹åˆ°GPU: NVIDIA GeForce RTX 3090
  CUDAç‰ˆæœ¬: 11.8
```

å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ° GPUï¼Œä¼šè‡ªåŠ¨é™çº§åˆ° CPUï¼š
```
âš  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ
```

---

### äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼

å¯åŠ¨äº¤äº’å¼æŸ¥è¯¢ç•Œé¢åï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

#### 1. åˆ—å‡ºæ‰€æœ‰å¯ç”¨çº¿è·¯
```
> list
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
å…±æœ‰ 5 æ¡çº¿è·¯:
  1. kyoto_nara-A
  2. kyoto_nara-B
  3. mt_fuji-A
  4. mt_fuji-C
  5. sea_of_kyoto-A
```

#### 2. æŸ¥è¯¢å•æ¡çº¿è·¯çš„é¢„æµ‹
```
> query <çº¿è·¯ID> <æ—¥æœŸ>

ç¤ºä¾‹ï¼š
> query kyoto_nara-A 2024-06-15
> query mt_fuji-A 2024/6/15
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
âœ“ é¢„æµ‹ç»“æœ:
  çº¿è·¯: kyoto_nara-A
  æ—¥æœŸ: 2024-06-15
  é¢„æµ‹äººæ•°: 1523
  å®é™…äººæ•°: 1500
  è¯¯å·®: 23 (1.5%)

å„æ¨¡å‹é¢„æµ‹:
  xgboost: 1520
  lightgbm: 1525
  ridge: 1520

é›†æˆæƒé‡:
  xgboost: 40.0%
  lightgbm: 40.0%
  ridge: 20.0%
```

#### 3. æŸ¥è¯¢æ—¥æœŸèŒƒå›´çš„é¢„æµ‹
```
> range <çº¿è·¯ID> <å¼€å§‹æ—¥æœŸ> <ç»“æŸæ—¥æœŸ>

ç¤ºä¾‹ï¼š
> range kyoto_nara-A 2024-06-01 2024-06-30
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
âœ“ é¢„æµ‹ç»“æœ (30 å¤©):
        date  prediction  actual  error
0 2024-06-01      1500    1512     -12
1 2024-06-02      1520    1505      15
2 2024-06-03      1480    1492     -12
...
```

#### 4. æ‰¹é‡æŸ¥è¯¢å¤šæ¡çº¿è·¯
```
> batch <æ—¥æœŸ> [çº¿è·¯1] [çº¿è·¯2] ...

ç¤ºä¾‹ï¼š
> batch 2024-06-15                    # æŸ¥è¯¢æ‰€æœ‰çº¿è·¯
> batch 2024-06-15 kyoto_nara-A mt_fuji-A  # æŸ¥è¯¢ç‰¹å®šçº¿è·¯
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
âœ“ æ‰¹é‡é¢„æµ‹ç»“æœ (5 æ¡çº¿è·¯):
       route_id  prediction  actual  error
0  kyoto_nara-A      1523   1500     23
1  kyoto_nara-B      1450   1430     20
2     mt_fuji-A      2100   2080     20
3     mt_fuji-C      1850   1870    -20
4 sea_of_kyoto-A      800    810    -10
```

#### 5. æ˜¾ç¤ºå¸®åŠ©
```
> help
```

#### 6. é€€å‡ºç¨‹åº
```
> exit
æˆ–
> quit
```

---

## ğŸ”§ API æ¥å£

### ä½¿ç”¨ Python ä»£ç è¿›è¡Œé¢„æµ‹

#### æ–¹æ³• 1: ç®€å•æŸ¥è¯¢
```python
from src.query_predict import query_single

# å•æ¬¡æŸ¥è¯¢
result = query_single('kyoto_nara-A', '2024-06-15')
print(f"é¢„æµ‹äººæ•°: {result['prediction']:.0f}")
```

#### æ–¹æ³• 2: åˆ›å»ºæŸ¥è¯¢å™¨å¯¹è±¡
```python
from src.query_predict import RoutePredictorQuery

# åˆå§‹åŒ–
predictor = RoutePredictorQuery()

# æŸ¥è¯¢å¯ç”¨çº¿è·¯
routes = predictor.list_routes()
print(f"å¯ç”¨çº¿è·¯: {routes}")

# å•æ¬¡é¢„æµ‹
prediction = predictor.predict('kyoto_nara-A', '2024-06-15')
print(f"é¢„æµ‹äººæ•°: {prediction:.0f}")

# è¯¦ç»†é¢„æµ‹ï¼ˆåŒ…å«å„æ¨¡å‹é¢„æµ‹å’Œè¯¯å·®ï¼‰
result = predictor.predict('kyoto_nara-A', '2024-06-15', return_details=True)
print(f"é¢„æµ‹: {result['prediction']:.0f}")
print(f"å®é™…: {result['actual']:.0f}")
print(f"è¯¯å·®: {result['error']:.0f}")
```

#### æ–¹æ³• 3: æ—¥æœŸèŒƒå›´æŸ¥è¯¢
```python
# æŸ¥è¯¢ä¸€ä¸ªæœˆçš„æ•°æ®
results_df = predictor.predict_range('kyoto_nara-A', '2024-06-01', '2024-06-30')
print(results_df)
```

#### æ–¹æ³• 4: æ‰¹é‡æŸ¥è¯¢
```python
# æŸ¥è¯¢æ‰€æœ‰çº¿è·¯
results = predictor.batch_predict('all', '2024-06-15')
print(results)

# æŸ¥è¯¢ç‰¹å®šçº¿è·¯
results = predictor.batch_predict(['kyoto_nara-A', 'mt_fuji-A'], '2024-06-15')
print(results)
```

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

è®­ç»ƒå®Œæˆåï¼Œåœ¨ `outputs/` ç›®å½•ä¸‹ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

### æ¨¡å‹æ–‡ä»¶
- `xgboost_model.pkl` - XGBoost æ¨¡å‹ï¼ˆå ç”¨çº¦ 5-10MBï¼‰
- `lightgbm_model.pkl` - LightGBM æ¨¡å‹ï¼ˆå ç”¨çº¦ 3-8MBï¼‰
- `ridge_model.pkl` - Ridge å›å½’æ¨¡å‹ï¼ˆå ç”¨çº¦ 1MBï¼‰

### é›†æˆé…ç½®æ–‡ä»¶
- `ensemble_weights.pkl` - é›†æˆæ¨¡å‹çš„æƒé‡
- `trainer.pkl` - è®­ç»ƒå™¨å¯¹è±¡ï¼ˆåŒ…å«å˜æ¢å‡½æ•°ï¼‰
- `feature_names.pkl` - ç‰¹å¾åç§°åˆ—è¡¨

### è¯„ä¼°å’Œåˆ†æ
- `evaluation_results.pkl` - æµ‹è¯•é›†ä¸Šçš„è¯„ä¼°ç»“æœ
- `xgboost_feature_importance.png` - XGBoost ç‰¹å¾é‡è¦æ€§å›¾
- `lightgbm_feature_importance.png` - LightGBM ç‰¹å¾é‡è¦æ€§å›¾

---

## âš™ï¸ æ€§èƒ½ä¼˜åŒ–

### GPU è®­ç»ƒçš„æ€§èƒ½å¯¹æ¯”

| å‚æ•° | CPU è®­ç»ƒ | GPU è®­ç»ƒ |
|------|---------|---------|
| XGBoost è®­ç»ƒæ—¶é—´ | ~30-60 ç§’ | ~5-10 ç§’ |
| LightGBM è®­ç»ƒæ—¶é—´ | ~20-40 ç§’ | ~3-8 ç§’ |
| æ€»è®­ç»ƒæ—¶é—´ | ~60-120 ç§’ | ~15-30 ç§’ |

### GPU é€‰æ‹©å»ºè®®
- **NVIDIA RTX 30 ç³»åˆ—æˆ–ä»¥ä¸Š**ï¼šå®Œæ•´æ”¯æŒï¼Œæ¨è
- **NVIDIA RTX 20 ç³»åˆ—**ï¼šåŸºæœ¬æ”¯æŒï¼Œå¯ç”¨
- **NVIDIA GTX 16 ç³»åˆ—**ï¼šåŸºæœ¬æ”¯æŒï¼Œå¯ç”¨
- **å…¶ä»–å‹å·**ï¼šéœ€è‡ªè¡ŒéªŒè¯é©±åŠ¨å’Œ CUDA æ”¯æŒ

---

## ğŸ› å¸¸è§é—®é¢˜

### Q: å‡ºç° "CUDA é”™è¯¯" æ€ä¹ˆåŠï¼Ÿ
**A:** 
1. æ£€æŸ¥ NVIDIA é©±åŠ¨ç‰ˆæœ¬ï¼š`nvidia-smi`
2. æ£€æŸ¥ PyTorch CUDA æ”¯æŒï¼š`python -c "import torch; print(torch.cuda.is_available())"`
3. å¦‚æœæœ‰é—®é¢˜ï¼Œä½¿ç”¨ CPU è®­ç»ƒï¼š`python quick_demo.py --mode train --no_gpu`

### Q: æŸ¥è¯¢æ—¶æ‰¾ä¸åˆ°æ•°æ®æ€ä¹ˆåŠï¼Ÿ
**A:**
1. æ£€æŸ¥çº¿è·¯ ID æ˜¯å¦æ­£ç¡®ï¼š`python quick_demo.py --mode query --interactive`ï¼Œç„¶åè¾“å…¥ `list`
2. æ£€æŸ¥æ—¥æœŸæ˜¯å¦åœ¨æ•°æ®èŒƒå›´å†…ï¼Œç³»ç»Ÿä¼šæ˜¾ç¤ºè¯¥çº¿è·¯çš„æ—¥æœŸèŒƒå›´
3. ç¡®ä¿æ•°æ®æ–‡ä»¶ `f:/Pytorch/Dataset/visitordata.csv` å­˜åœ¨

### Q: é¢„æµ‹ç»“æœçš„å‡†ç¡®æ€§å¦‚ä½•ï¼Ÿ
**A:**
- RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰ï¼šé€šå¸¸åœ¨ 100-500 ä¹‹é—´
- RÂ² åˆ†æ•°ï¼šé€šå¸¸åœ¨ 0.7-0.9 ä¹‹é—´
- å®é™…å‡†ç¡®æ€§å–å†³äºæ•°æ®è´¨é‡å’Œçº¿è·¯ç‰¹å¾

### Q: å¯ä»¥ä¿®æ”¹æ¨¡å‹å‚æ•°å—ï¼Ÿ
**A:** å¯ä»¥ï¼Œä¿®æ”¹ `configs/model_config.yaml` æ–‡ä»¶ï¼š
```yaml
training:
  xgboost:
    max_depth: 4          # æ ‘çš„æœ€å¤§æ·±åº¦
    learning_rate: 0.05   # å­¦ä¹ ç‡
    n_estimators: 500     # æ ‘çš„æ•°é‡
    reg_alpha: 1.0        # L1 æ­£åˆ™åŒ–
    reg_lambda: 2.0       # L2 æ­£åˆ™åŒ–
```

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- `quick_demo.py` - ä¸»æ¼”ç¤ºè„šæœ¬ï¼ˆæœ¬æ–‡ä»¶ï¼‰
- `src/train.py` - è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒ GPUï¼‰
- `src/query_predict.py` - æŸ¥è¯¢é¢„æµ‹æ¨¡å—
- `src/models/tree_models.py` - æ ‘æ¨¡å‹å®ç°
- `src/models/ensemble.py` - é›†æˆæ¨¡å‹å®ç°
- `configs/model_config.yaml` - æ¨¡å‹é…ç½®æ–‡ä»¶

---

## ğŸš€ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰è®­ç»ƒ
```python
from src.train import load_config, main
import torch

# æ£€æŸ¥ GPU
print(f"GPU Available: {torch.cuda.is_available()}")

# ä½¿ç”¨ GPU è®­ç»ƒ
main(use_gpu=True)
```

### ç»“æœå¯¼å‡º
```python
from src.query_predict import RoutePredictorQuery
import pandas as pd

predictor = RoutePredictorQuery()

# è·å–æ•´ä¸ªæœˆçš„é¢„æµ‹
results = predictor.predict_range('kyoto_nara-A', '2024-06-01', '2024-06-30')

# ä¿å­˜ä¸º CSV
results.to_csv('predictions_2024_06.csv', index=False)
```

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
